{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses, metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from data_split import data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "trajs_from_files = csv.reader(open('challenge_for_scoring/task3.txt','r'), delimiter=';', \n",
    "                                        lineterminator='\\n',quoting=csv.QUOTE_NONNUMERIC)\n",
    "validation = [[],[],[]]\n",
    "for trajs in enumerate(trajs_from_files):\n",
    "    validation[int(trajs[1][0])-1].append(trajs[1][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the networks, two (three) for inference of exponents and switching times, one for classification of first model, one for classification of second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_switch_a_t_new = load_model('nets/task3/1d/task3_new.h5')\n",
    "\n",
    "model_switch_a_t_diff = load_model('nets/task3/1d/diff_task3.h5')\n",
    "\n",
    "model_classi_first = load_model('nets/task3/1d/taks_3_classify_frst_checkout200.h5')\n",
    "\n",
    "model_classi_sec = load_model('nets/task3/1d/taks_3_classify_second_checkout200.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personalized arctan to convert predictions into switching times stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_atan(x1,x2):\n",
    "    y=np.arctan2(x1,x2)\n",
    "    b=y<0\n",
    "    c=b.astype(int)*(2*np.pi)\n",
    "    d=y+c \n",
    "    return    d;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1d case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the model works using the positions as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 1d\n",
    "i=200\n",
    "validation1d=validation[0]\n",
    "test_tim_step=np.arange(200)\n",
    "show_time_coll=np.tile(test_tim_step,(len(validation1d),1))\n",
    "data_show,label_show,traj_show,times_show=data_split(np.asarray(validation1d),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation1d)),\n",
    "                                                         start_row=0,num_row=len(validation1d),\n",
    "                                                         traj_len=np.asarray(validation1d).shape[1],n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "pred_a_t_new=model_switch_a_t_new(data_show)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other models take the increments as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=200\n",
    "\n",
    "data_show_diff,label_show,traj_show,times_show=data_split(np.diff(np.asarray(validation1d),axis=1),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation1d)),\n",
    "                                                         start_row=0,num_row=len(validation1d),\n",
    "                                                         traj_len=i-1,n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "pred_a_t_diff=model_switch_a_t_diff.predict(data_show_diff)\n",
    "\n",
    "pred_m1_first=np.argmax(model_classi_first.predict(data_show_diff),axis=1)\n",
    "\n",
    "pred_m2_sec=np.argmax(model_classi_sec.predict(data_show_diff),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions for the switching times are made by taking the average of the 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_diff = my_atan(pred_a_t_diff[:,2],pred_a_t_diff[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_comb = (pr_t_new+pr_t_diff)/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_m1s=np.copy(pred_m1_first)\n",
    "pred_m2s=np.copy(pred_m2_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the total prediction array  in the format required by submission, giving (t,model 1,a1,model2,a2). t is obtained avearging 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1d=np.zeros((len(validation1d),5))\n",
    "predictions1d[:,0]=pr_t_comb\n",
    "predictions1d[:,1]=pred_m1s\n",
    "predictions1d[:,2]=(pred_a_t_new[:,0]+pred_a_t_diff[:,0])/2\n",
    "predictions1d[:,3]=pred_m2s\n",
    "predictions1d[:,4]=(pred_a_t_new[:,1]+pred_a_t_diff[:,1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predictions/task3/task3_predictions1d_final.npy',predictions1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt1d = 1*np.ones((len(predictions1d), 6))\n",
    "for i in range(len(predictions1d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt1d[i, j+1] = predictions1d[i][j]\n",
    "pred_to_txt = pred_to_txt1d\n",
    "#np.savetxt('task3_tem1d_new.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative version, it performed better. For both inference and model detection it is obtained by applying the 1d classifier and averging all dimension independently, we know this may not work well for LW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=200\n",
    "for dim in [2]:\n",
    "    pred_hd_a_t=np.zeros((len(validation[1]),3))\n",
    "    \n",
    "    pred_hd_m1_first=np.zeros((len(validation[1]),5))\n",
    "    \n",
    "    pred_hd_m2_sec=np.zeros((len(validation[1]),5))\n",
    "    \n",
    "    valid_ch_dim=np.asarray(validation[dim-1])    #validation in the chosen dimension\n",
    "    for jj in range(dim):\n",
    "        x=valid_ch_dim[:,i*jj:i*(jj+1)]\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(x),1))\n",
    "        data_show,label_show,traj_show,times_show=data_split(x,\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1],n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "\n",
    "        pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "        pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "        pred_hd_a_t[:,:2]+=pred_a_t_new[:,:2]/dim\n",
    "        pred_hd_a_t[:,2]+=pr_t_new/dim\n",
    "        \n",
    "        #model classification uses increments\n",
    "\n",
    "        \n",
    "        data_show_diff,label_show,traj_show_diff,times_show=data_split(np.diff(x,axis=1),\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1]-1,n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        #first model\n",
    "        pred_m1_first=model_classi_first.predict(data_show_diff)\n",
    "        pred_hd_m1_first+=pred_m1_first/dim\n",
    "        \n",
    "        \n",
    "        #second model\n",
    "\n",
    "        pred_m2_sec=model_classi_sec.predict(data_show_diff)\n",
    "        pred_hd_m2_sec+=pred_m2_sec/dim\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the total prediction array  in the format required by submission, giving (t,model 1,a1,model2,a2). For inference, only model new is used and its predictions are averaged in the different dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2d=np.zeros((len(validation[1]),5))\n",
    "predictions2d[:,0]=pred_hd_a_t[:,2] # t switch\n",
    "predictions2d[:,1]=np.argmax(pred_hd_m1_first,axis=1)\n",
    "predictions2d[:,2]=pred_hd_a_t[:,0]  # a1\n",
    "predictions2d[:,3]=np.argmax(pred_hd_m2_sec,axis=1)\n",
    "predictions2d[:,4]=pred_hd_a_t[:,1]  #a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predictions/task3/task3_predictions2d.npy',predictions2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt2d = 2*np.ones((len(predictions2d), 6))\n",
    "for i in range(len(predictions2d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt2d[i, j+1] = predictions2d[i][j]\n",
    "pred_to_txt = np.concatenate((pred_to_txt1d,pred_to_txt2d))\n",
    "#np.savetxt('task3_tem2d.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we again use the alternative version were the 3d data is just an average of the 1d nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 3d\n",
    "i=200\n",
    "for dim in [3]:\n",
    "    pred_hd_a_t=np.zeros((len(validation[0]),3))\n",
    "    \n",
    "    pred_hd_m1_first=np.zeros((len(validation[0]),5))\n",
    "    pred_hd_m2_sec=np.zeros((len(validation[0]),5))\n",
    "    valid_ch_dim=np.asarray(validation[dim-1])    #validation in the chosen dimension\n",
    "    for jj in range(dim):\n",
    "        x=valid_ch_dim[:,i*jj:i*(jj+1)]\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(x),1))\n",
    "        data_show,label_show,traj_show,times_show=data_split(x,\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1],n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        \n",
    "        pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "        pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "        pred_hd_a_t[:,:2]+=pred_a_t_new[:,:2]/dim\n",
    "        pred_hd_a_t[:,2]+=pr_t_new/dim\n",
    "        \n",
    "#         #model classification\n",
    "\n",
    "       \n",
    "        data_show_diff,label_show,traj_show_diff,times_show=data_split(np.diff(x,axis=1),\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1]-1,n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        #first model\n",
    "        pred_m1_first=model_classi_first.predict(data_show_diff)\n",
    "        pred_hd_m1_first+=pred_m1_first/dim\n",
    "        \n",
    "        \n",
    "        #second model\n",
    "\n",
    "        pred_m2_sec=model_classi_sec.predict(data_show_diff)\n",
    "        pred_hd_m2_sec+=pred_m2_sec/dim\n",
    "                        \n",
    "        \n",
    "        \n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the total prediction array  in the format required by submission, giving (t,model 1,a1,model2,a2). For inference, only model new is used and its predictions are averaged in the different dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3d=np.zeros((len(validation[0]),5))\n",
    "predictions3d[:,0]=pred_hd_a_t[:,2]  # t switch\n",
    "predictions3d[:,1]=np.argmax(pred_hd_m1_first,axis=1)\n",
    "predictions3d[:,2]=pred_hd_a_t[:,0]  # a1\n",
    "predictions3d[:,3]=np.argmax(pred_hd_m2_sec,axis=1)\n",
    "predictions3d[:,4]=pred_hd_a_t[:,1]  #a2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predictions/task3/task3_predictions3d.npy',predictions3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt3d = 3*np.ones((len(predictions3d), 6))\n",
    "for i in range(len(predictions3d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt3d[i, j+1] = predictions3d[i][j]\n",
    "pred_to_txt_fin = np.concatenate((pred_to_txt,pred_to_txt3d))\n",
    "np.savetxt('best_sub/task3.txt', pred_to_txt_fin.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
