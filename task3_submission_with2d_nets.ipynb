{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses, metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from data_split import data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For inference in 2d we are using the new nets trained on correct 2d data. 2d nets trained and test on wrong data were used during the original submission but were performing worse than the combination of 1d nets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "trajs_from_files = csv.reader(open('challenge_for_scoring/task3.txt','r'), delimiter=';', \n",
    "                                        lineterminator='\\n',quoting=csv.QUOTE_NONNUMERIC)\n",
    "validation = [[],[],[]]\n",
    "for trajs in enumerate(trajs_from_files):\n",
    "    validation[int(trajs[1][0])-1].append(trajs[1][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the networks, two (three) for inference of exponents and switching times, one for classification of first model, one for classification of second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_switch_a_t_new = load_model('nets/task3/1d/task3_new.h5')\n",
    "\n",
    "model_switch_a_t_diff = load_model('nets/task3/1d/diff_task3.h5')\n",
    "\n",
    "model_classi_first = load_model('nets/task3/1d/taks_3_classify_frst_checkout200.h5')\n",
    "\n",
    "model_classi_sec = load_model('nets/task3/1d/taks_3_classify_second_checkout200.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personalized arctan to convert predictions into switching times stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_atan(x1,x2):\n",
    "    y=np.arctan2(x1,x2)\n",
    "    b=y<0\n",
    "    c=b.astype(int)*(2*np.pi)\n",
    "    d=y+c \n",
    "    return    d;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1d case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the model works using the positions as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 1d\n",
    "i=200\n",
    "validation1d=validation[0]\n",
    "test_tim_step=np.arange(200)\n",
    "show_time_coll=np.tile(test_tim_step,(len(validation1d),1))\n",
    "data_show,label_show,traj_show,times_show=data_split(np.asarray(validation1d),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation1d)),\n",
    "                                                         start_row=0,num_row=len(validation1d),\n",
    "                                                         traj_len=np.asarray(validation1d).shape[1],n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "pred_a_t_new=model_switch_a_t_new(data_show)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other models take the increments as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=200\n",
    "\n",
    "data_show_diff,label_show,traj_show,times_show=data_split(np.diff(np.asarray(validation1d),axis=1),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation1d)),\n",
    "                                                         start_row=0,num_row=len(validation1d),\n",
    "                                                         traj_len=i-1,n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "pred_a_t_diff=model_switch_a_t_diff.predict(data_show_diff)\n",
    "\n",
    "pred_m1_first=np.argmax(model_classi_first.predict(data_show_diff),axis=1)\n",
    "\n",
    "pred_m2_sec=np.argmax(model_classi_sec.predict(data_show_diff),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions for the switching times are made by taking the average of the 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_diff = my_atan(pred_a_t_diff[:,2],pred_a_t_diff[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_comb = (pr_t_new+pr_t_diff)/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_m1s=np.copy(pred_m1_first)\n",
    "pred_m2s=np.copy(pred_m2_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the total prediction array  in the format required by submission, giving (t,model 1,a1,model2,a2). t is obtained avearging 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1d=np.zeros((len(validation1d),5))\n",
    "predictions1d[:,0]=pr_t_comb\n",
    "predictions1d[:,1]=pred_m1s\n",
    "predictions1d[:,2]=(pred_a_t_new[:,0]+pred_a_t_diff[:,0])/2\n",
    "predictions1d[:,3]=pred_m2s\n",
    "predictions1d[:,4]=(pred_a_t_new[:,1]+pred_a_t_diff[:,1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predictions/task3/task3_predictions1d_final.npy',predictions1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt1d = 1*np.ones((len(predictions1d), 6))\n",
    "for i in range(len(predictions1d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt1d[i, j+1] = predictions1d[i][j]\n",
    "pred_to_txt = pred_to_txt1d\n",
    "#np.savetxt('task3_tem1d_new.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to normalize and reshape higher dimensional trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_norm(traj_set,dim,task,thr=1e-10):  \n",
    "    \n",
    "    '''function to normalize a set of trajectories of the same length l.\n",
    "    takes as input a vector of length N l*dim \n",
    "    for segmenation task, set task=3. It returns array of normalized displacements of dimension (N,dim,l-1)\n",
    "    for other tasks, it returns array of normalized displacements of dimension (N,dim,l) where the last entries are all 0\n",
    "\n",
    "    '''\n",
    "        \n",
    "    N = len(traj_set)\n",
    "    r = np.array(traj_set).reshape(N,dim,-1)  \n",
    "    r_3 = np.copy(r)\n",
    "    r = np.diff(r,axis=2)                              # get the increments\n",
    "\n",
    "    for dm in range(dim):\n",
    "        x = np.copy(r[:,dm,:])                                     # get x data\n",
    "        sx = np.std(x,axis=1)                           \n",
    "        x = (x-np.mean(x,axis=1).reshape(len(x),1)) / np.where(sx>thr,sx,1).reshape(len(x),1)   # normalize x data\n",
    "        if task == 3:\n",
    "            x =  np.concatenate((x,np.zeros((N,1))),axis=1)         #if the task is 3, each dimension of the trajectory gets a 0 at the end\n",
    "\n",
    "            r_3[:,dm,:]  = np.copy(x)\n",
    "        else:    \n",
    "            r[:,dm,:]  = np.copy(x)\n",
    "\n",
    "\n",
    "    if task == 3:\n",
    "        \n",
    "        return r_3\n",
    "    else:\n",
    "        return r\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reshape(r,bs,dim):  \n",
    "    \n",
    "    '''function to prepare a set of trajectories of the same length into\n",
    "    the shape required by the network. bs is the block size. \n",
    "    takes as input array of normalized displacements of dimension (N,dim,js)\n",
    "    The function automatically cuts the trajectory to\n",
    "    the largest multiple of bs. The reshaping e.g. for a 2-dimensional trajectory\n",
    "    for a net working on blocks of dimension 4 gives the trajectory reshaped as\n",
    "    { [x0,y0, x1, y1], [x2,y2, x3,y3], ...} '''\n",
    "            \n",
    "    js = r.shape[-1]\n",
    "    N = r.shape[0]\n",
    "\n",
    "\n",
    "    rl=int(dim*(js)/bs)*int(bs/dim)  #cutting the trajectory to fit to  multiple of dimensione used by net\n",
    "\n",
    "\n",
    "    rt = np.transpose(r[:,:,:rl],axes = [0,2,1])\n",
    "#         print(rl, rt.shape)\n",
    "    rs_traj = rt.reshape(N,-1,bs)\n",
    "    \n",
    "    return rs_traj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the 2d net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_switch_a_t_2d = load_model('nets/task3/2d/T32D_inf_nd.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For inference of exponents and change-point we apply the net trained on 2d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_set = validation[1]\n",
    "\n",
    "#finding out the block size used by the chosen net\n",
    "bs = model_switch_a_t_2d.layers[0].input_shape[-1]\n",
    "\n",
    "#normalizing the data\n",
    "data = data_norm(traj_set,dim=2,task=3)\n",
    "\n",
    "\n",
    "#reshaping the data\n",
    "\n",
    "data_rs = data_reshape(data,bs=bs,dim=2)\n",
    "\n",
    "inf2d_seg = model_switch_a_t_2d.predict(data_rs)\n",
    "\n",
    "pred2d_t = my_atan(inf2d_seg[:,2],inf2d_seg[:,3])*200/(2*np.pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model detection it is obtained by applying the 1d classifier and averging all dimension independently, we know this may not work well for LW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=200\n",
    "for dim in [2]:\n",
    "#     pred_hd_a_t=np.zeros((len(validation[1]),3))\n",
    "    \n",
    "    pred_hd_m1_first=np.zeros((len(validation[1]),5))\n",
    "    \n",
    "    pred_hd_m2_sec=np.zeros((len(validation[1]),5))\n",
    "    \n",
    "    valid_ch_dim=np.asarray(validation[dim-1])    #validation in the chosen dimension\n",
    "    for jj in range(dim):\n",
    "        x=valid_ch_dim[:,i*jj:i*(jj+1)]\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(x),1))\n",
    "#         data_show,label_show,traj_show,times_show=data_split(x,\n",
    "#                                                              show_time_coll,\n",
    "#                                                                  labels=np.ones(len(x)),\n",
    "#                                                                  start_row=0,num_row=len(x),\n",
    "#                                                                  traj_len=x.shape[1],n_in=0,n_samples=1,\n",
    "#                                                                  p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "\n",
    "#         pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "#         pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "#         pred_hd_a_t[:,:2]+=pred_a_t_new[:,:2]/dim\n",
    "#         pred_hd_a_t[:,2]+=pr_t_new/dim\n",
    "        \n",
    "        #model classification uses increments\n",
    "\n",
    "        \n",
    "        data_show_diff,label_show,traj_show_diff,times_show=data_split(np.diff(x,axis=1),\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1]-1,n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        #first model\n",
    "        pred_m1_first=model_classi_first.predict(data_show_diff)\n",
    "        pred_hd_m1_first+=pred_m1_first/dim\n",
    "        \n",
    "        \n",
    "        #second model\n",
    "\n",
    "        pred_m2_sec=model_classi_sec.predict(data_show_diff)\n",
    "        pred_hd_m2_sec+=pred_m2_sec/dim\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the total prediction array  in the format required by submission, giving (t,model 1,a1,model2,a2). For inference, only model new is used and its predictions are averaged in the different dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2d=np.zeros((len(validation[1]),5))\n",
    "predictions2d[:,0]=pred2d_t # t switch\n",
    "predictions2d[:,1]=np.argmax(pred_hd_m1_first,axis=1)\n",
    "predictions2d[:,2]=inf2d_seg[:,0]  # a1\n",
    "predictions2d[:,3]=np.argmax(pred_hd_m2_sec,axis=1)\n",
    "predictions2d[:,4]=inf2d_seg[:,1]  #a2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predictions/task3/task3_predictions2d_new_nets.npy',predictions2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt2d = 2*np.ones((len(predictions2d), 6))\n",
    "for i in range(len(predictions2d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt2d[i, j+1] = predictions2d[i][j]\n",
    "pred_to_txt = np.concatenate((pred_to_txt1d,pred_to_txt2d))\n",
    "#np.savetxt('task3_tem2d.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we again use the alternative version were the 3d data is just an average of the 1d nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 3d\n",
    "i=200\n",
    "for dim in [3]:\n",
    "    pred_hd_a_t=np.zeros((len(validation[0]),3))\n",
    "    \n",
    "    pred_hd_m1_first=np.zeros((len(validation[0]),5))\n",
    "    pred_hd_m2_sec=np.zeros((len(validation[0]),5))\n",
    "    valid_ch_dim=np.asarray(validation[dim-1])    #validation in the chosen dimension\n",
    "    for jj in range(dim):\n",
    "        x=valid_ch_dim[:,i*jj:i*(jj+1)]\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(x),1))\n",
    "        data_show,label_show,traj_show,times_show=data_split(x,\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1],n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        \n",
    "        pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "        pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "        pred_hd_a_t[:,:2]+=pred_a_t_new[:,:2]/dim\n",
    "        pred_hd_a_t[:,2]+=pr_t_new/dim\n",
    "        \n",
    "#         #model classification\n",
    "\n",
    "       \n",
    "        data_show_diff,label_show,traj_show_diff,times_show=data_split(np.diff(x,axis=1),\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1]-1,n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        #first model\n",
    "        pred_m1_first=model_classi_first.predict(data_show_diff)\n",
    "        pred_hd_m1_first+=pred_m1_first/dim\n",
    "        \n",
    "        \n",
    "        #second model\n",
    "\n",
    "        pred_m2_sec=model_classi_sec.predict(data_show_diff)\n",
    "        pred_hd_m2_sec+=pred_m2_sec/dim\n",
    "                        \n",
    "        \n",
    "        \n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the total prediction array  in the format required by submission, giving (t,model 1,a1,model2,a2). For inference, only model new is used and its predictions are averaged in the different dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3d=np.zeros((len(validation[0]),5))\n",
    "predictions3d[:,0]=pred_hd_a_t[:,2]  # t switch\n",
    "predictions3d[:,1]=np.argmax(pred_hd_m1_first,axis=1)\n",
    "predictions3d[:,2]=pred_hd_a_t[:,0]  # a1\n",
    "predictions3d[:,3]=np.argmax(pred_hd_m2_sec,axis=1)\n",
    "predictions3d[:,4]=pred_hd_a_t[:,1]  #a2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predictions/task3/task3_predictions3d.npy',predictions3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt3d = 3*np.ones((len(predictions3d), 6))\n",
    "for i in range(len(predictions3d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt3d[i, j+1] = predictions3d[i][j]\n",
    "pred_to_txt_fin = np.concatenate((pred_to_txt,pred_to_txt3d))\n",
    "np.savetxt('best_sub/task3.txt', pred_to_txt_fin.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
